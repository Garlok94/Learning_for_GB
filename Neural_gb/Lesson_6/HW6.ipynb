{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f52336fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install opencv-python\n",
    "# !pip install -q kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3fa151d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9238e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir ~/.kaggle\n",
    "!cp kaggle.json ~/.kaggle/\n",
    "!chmod 600 ~/.kaggle/kaggle.json\n",
    "# !kaggle datasets list\n",
    "!kaggle datasets download -d 'dansbecker/cityscapes-image-pairs'\n",
    "!unzip cityscapes-image-pairs.zip -d cityscapes-image-pairs\n",
    "!rm -R cityscapes-image-pairs/cityscapes_data/cityscapes_data/\n",
    "!mv cityscapes-image-pairs/cityscapes_data/train cityscapes-image-pairs\n",
    "!mv cityscapes-image-pairs/cityscapes_data/val cityscapes-image-pairs\n",
    "!rm -R cityscapes-image-pairs/cityscapes_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f1a894d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 \n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "import keras\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers import (Input, Dense, Dropout, Activation, Flatten, Convolution2D, \n",
    "                          MaxPooling2D, UpSampling2D, Conv2DTranspose, concatenate)\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.models import Sequential, Model, model_from_json, load_model\n",
    "from keras.regularizers import l2\n",
    "from keras.preprocessing import image\n",
    "from keras.optimizers import Adam\n",
    "In [4]:\n",
    "path = '/content/cityscapes-image-pairs/train/'\n",
    "if os.path.isfile(path):\n",
    "    img1 = cv2.imread(path, 0)\n",
    "else:\n",
    "    print (\"The file \" + path + \" does not exist.\")\n",
    "\n",
    "flist = os.listdir(path)\n",
    "img0 = cv2.imread(path+flist[0])\n",
    "plt.imshow(img0)\n",
    "print(np.shape(img0))\n",
    "print(len(flist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f067d8c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# чтение картинок и создание тренировочного датасета\n",
    "szy, szx, _ = np.shape(img0)\n",
    "N_ex = 500 # берём часть датасета, чтобы нейронке хватило памяти\n",
    "N_bias = 0\n",
    "x_train = np.zeros((N_ex, szy, int(szx/2), 3))\n",
    "y_train = np.zeros((N_ex, szy, int(szx/2), 3))\n",
    "k = 0\n",
    "\n",
    "for f in flist[N_bias:N_bias+N_ex]:\n",
    "    x_train[k] = cv2.imread(path+f)[:,:256]/256\n",
    "    y_train[k] = cv2.imread(path+f)[:,256:]/256\n",
    "    k = k+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21147ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (15,15))\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(x_train[0])\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(y_train[0]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0760a926",
   "metadata": {},
   "outputs": [],
   "source": [
    "# то же самое для тренировочных данных\n",
    "path = '/content/cityscapes-image-pairs/val/'\n",
    "\n",
    "if os.path.isfile(path):\n",
    "    img1 = cv2.imread(path, 0)\n",
    "else:\n",
    "    print (\"The file \" + path + \" does not exist.\")\n",
    "\n",
    "flist = os.listdir(path)\n",
    "img0 = cv2.imread(path+flist[0])\n",
    "N_val = 50  # берём часть датасета, чтобы нейронке хватило памяти\n",
    "\n",
    "szy,szx,_ = np.shape(img0)\n",
    "x_val = np.zeros((N_val,szy,int(szx/2),3))\n",
    "y_val = np.zeros((N_val,szy,int(szx/2),3))\n",
    "k = 0;\n",
    "\n",
    "for f in flist[0:N_val]:\n",
    "    x_val[k] = cv2.imread(path+f)[:,:256]/256\n",
    "    y_val[k] = cv2.imread(path+f)[:,256:]/256\n",
    "    k = k+1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e3f1b9c",
   "metadata": {},
   "source": [
    "Unet 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61613f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "# функции нужно писать не на Numpy, а на бекэнде, на котором запущен keras, в данном случае на TensorFlow\n",
    "\n",
    "def dice_coef(y_true, y_pred):\n",
    "    return (2. * K.sum(y_true * y_pred)) / (K.sum(y_true) + K.sum(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ce914d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#u-net architecture\n",
    "\n",
    "# define conv_factory: batch normalization + ReLU + Conv2D + Dropout (optional)\n",
    "def conv_factory(x, concat_axis, nb_filter,\n",
    "                 dropout_rate=None, weight_decay=1E-4):\n",
    "    x = BatchNormalization(axis=concat_axis,\n",
    "                           gamma_regularizer=l2(weight_decay),\n",
    "                           beta_regularizer=l2(weight_decay))(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv2D(nb_filter, (5, 5), dilation_rate=(2, 2),\n",
    "               kernel_initializer=\"he_uniform\",\n",
    "               padding=\"same\",\n",
    "               kernel_regularizer=l2(weight_decay))(x)\n",
    "    if dropout_rate:\n",
    "        x = Dropout(dropout_rate)(x)\n",
    "  \n",
    "    return x\n",
    "\n",
    "\n",
    "# define dense block: a nb_layers stack of conv_factory layers merged together\n",
    "def denseblock(x, concat_axis, nb_layers, growth_rate, dropout_rate=None, weight_decay=1E-4):\n",
    "    list_feat = [x]\n",
    "    for i in range(nb_layers):\n",
    "        x = conv_factory(x, concat_axis, growth_rate,dropout_rate, weight_decay)\n",
    "        list_feat.append(x)\n",
    "    x = Concatenate(axis=concat_axis)(list_feat)\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "# define model U-net modified with dense block\n",
    "def u_net():\n",
    "    dr = 0.5\n",
    "    nr = 2\n",
    "    mod_inputs = Input((256,256,3))\n",
    "    print(\"inputs shape:\", mod_inputs.shape) #input layer\n",
    "\n",
    "    conv1 = Conv2D(64/nr, 3, activation='relu', padding='same', kernel_initializer='he_normal')(mod_inputs)\n",
    "    print(\"conv1 shape:\", conv1.shape)\n",
    "    db1 = denseblock(x=conv1, concat_axis=3, nb_layers=4, growth_rate=16, dropout_rate=dr)\n",
    "    print(\"db1 shape:\", db1.shape)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(db1)\n",
    "    print(\"pool1 shape:\", pool1.shape)\n",
    "\n",
    "    conv2 = Conv2D(128/nr, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool1)\n",
    "    print(\"conv2 shape:\", conv2.shape)\n",
    "    db2 = denseblock(x=conv2, concat_axis=3, nb_layers=4, growth_rate=16, dropout_rate=dr)\n",
    "    print(\"db2 shape:\", db2.shape)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(db2)\n",
    "    print(\"pool2 shape:\", pool2.shape)\n",
    "\n",
    "    conv3 = Conv2D(256/nr, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool2)\n",
    "    print(\"conv3 shape:\", conv3.shape)\n",
    "    db3 = denseblock(x=conv3, concat_axis=3, nb_layers=4, growth_rate=16, dropout_rate=dr)\n",
    "    print(\"db3 shape:\", db3.shape)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(db3)\n",
    "    print(\"pool3 shape:\", pool3.shape)\n",
    "\n",
    "    conv4 = Conv2D(512/nr, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool3)\n",
    "    print(\"conv4 shape:\", conv4.shape)\n",
    "    db4 = denseblock(x=conv4, concat_axis=3, nb_layers=4, growth_rate=16, dropout_rate=dr)\n",
    "    print(\"db4 shape:\", db4.shape)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(db4)\n",
    "    print(\"pool4 shape:\", pool4.shape)\n",
    "#################this is the bottleneck######################################\n",
    "    conv5 = Conv2D(1024/nr, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool4)\n",
    "    print(\"conv5 shape:\", conv5.shape)\n",
    "    db5 = denseblock(x=conv5, concat_axis=3, nb_layers=3, growth_rate=16, dropout_rate=dr)\n",
    "    print(\"db5 shape:\", db5.shape)\n",
    "    up5 = Conv2D(512/nr, 2, activation='relu', padding='same', kernel_initializer='he_normal')(UpSampling2D(size=(2, 2))(db5))\n",
    "    print(\"up5 shape:\", up5.shape)\n",
    "    merge5 = Concatenate(axis=3)([ BatchNormalization()(db4), BatchNormalization()( up5)]) #skip connection db4 to up5\n",
    "    print(\"merge5 shape:\", merge5.shape)\n",
    "\n",
    "    conv6 = Conv2D(512, 3, activation='relu', padding='same', kernel_initializer='he_normal')(merge5)\n",
    "    print(\"conv6 shape:\", conv6.shape)\n",
    "    db6 = denseblock(x=conv6, concat_axis=3, nb_layers=3, growth_rate=16, dropout_rate=dr)\n",
    "    print(\"db5 shape:\", db6.shape)\n",
    "    up6 = Conv2D(256/nr, 2, activation='relu', padding='same', kernel_initializer='he_normal')(UpSampling2D(size=(2, 2))(db6))\n",
    "    print(\"up6 shape:\", up6.shape)\n",
    "    merge6 = Concatenate(axis=3)([BatchNormalization()(db3), BatchNormalization()(up6)]) #skip connection db3 to up6\n",
    "    print(\"merge6 shape:\", merge6.shape)\n",
    "\n",
    "    conv7 = Conv2D(256/nr, 3, activation='relu', padding='same', kernel_initializer='he_normal')(merge6)\n",
    "    print(\"conv7 shape:\", conv7.shape)\n",
    "    db7 = denseblock(x=conv7, concat_axis=3, nb_layers=2, growth_rate=16, dropout_rate=dr)\n",
    "    print(\"db7 shape:\", db7.shape)\n",
    "    up7 = Conv2D(128/nr, 2, activation='relu', padding='same', kernel_initializer='he_normal')(\n",
    "        UpSampling2D(size=(2, 2))(db7))\n",
    "    print(\"up7 shape:\", up7.shape)\n",
    "    merge7 = Concatenate(axis=3)([BatchNormalization()(db2), BatchNormalization()(up7)]) #skip connection db2 to up7\n",
    "    print(\"merge7 shape:\", merge7.shape)\n",
    "\n",
    "    conv8 = Conv2D(128/nr, 3, activation='relu', padding='same', kernel_initializer='he_normal')(merge7)\n",
    "    print(\"conv8 shape:\", conv8.shape)\n",
    "    db8 = denseblock(x=conv8, concat_axis=3, nb_layers=2, growth_rate=16, dropout_rate=dr)\n",
    "    print(\"db8 shape:\", db8.shape)\n",
    "    up8 = Conv2D(64/nr, 2, activation='relu', padding='same', kernel_initializer='he_normal')(\n",
    "        UpSampling2D(size=(2, 2))(db8))\n",
    "    print(\"up8 shape:\", up8.shape)\n",
    "    merge8 = Concatenate(axis=3)([BatchNormalization()(db1), BatchNormalization()(up8)]) #skip connection db1 to up8\n",
    "    print(\"merge8 shape:\", merge8.shape)\n",
    "\n",
    "    conv9 = Conv2D(64/nr, 3, activation='relu', padding='same', kernel_initializer='he_normal')(merge8)\n",
    "    print(\"conv9 shape:\", conv9.shape)\n",
    "    db9 = denseblock(x=conv9, concat_axis=3, nb_layers=2, growth_rate=16, dropout_rate=dr)\n",
    "    print(\"db9 shape:\", db9.shape)\n",
    "    conv10 = Conv2D(32/nr, 3, activation='relu', padding='same', kernel_initializer='he_normal')(db9) # final node layer\n",
    "    print(\"conv10 shape:\", conv10.shape)\n",
    "    conv11 = Conv2D(3, 1, activation='sigmoid')(conv10)  #output layer matched in size with the input\n",
    "    print(\"conv11 shape:\", conv11.shape)\n",
    "\n",
    "    model = Model(inputs=mod_inputs, outputs=conv11) \n",
    "    model.compile(optimizer='adam', \n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=[dice_coef],           # самописная метрика dice\n",
    "                  )      \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434670c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = u_net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c4cff05",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ece497a",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = model.fit(x_train, y_train, epochs=50, shuffle = True, batch_size=10, validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f58e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0821066",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(hist.history['loss'], label='train_loss')\n",
    "plt.plot(hist.history['val_loss'], label='val_loss')\n",
    "plt.legend()\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc67067",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(hist.history['val_dice_coef'], label='test')\n",
    "plt.plot(hist.history['dice_coef'], label='train')\n",
    "plt.legend()\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('dice_coef')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99fde49d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(x_val)\n",
    "print(pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c782d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ni = 3\n",
    "for k in range(ni):\n",
    "    plt.figure(figsize=(20,60))\n",
    "\n",
    "    plt.subplot(ni,4,1+k*4)\n",
    "    plt.imshow(x_val[k])\n",
    "\n",
    "    plt.subplot(ni,4,2+k*4)\n",
    "    plt.imshow(y_val[k])\n",
    "\n",
    "    plt.subplot(ni,4,3+k*4)\n",
    "    plt.imshow(pred[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dbbacd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_predictions(model):\n",
    "\n",
    "    sample_image = x_val[0]\n",
    "    sample_mask = y_val[0]\n",
    "\n",
    "    pred_mask = model.predict(sample_image[None])[..., 0] # нулевой канал, можно любой (можно которого больше)\n",
    "    print(pred_mask.shape)\n",
    "\n",
    "    fig, ax = plt.subplots(1, 3, figsize=(15, 8))\n",
    "\n",
    "    ax[0].imshow(sample_image) # картинка\n",
    "    ax[1].imshow(sample_mask[..., 0]) # истиная маска\n",
    "    ax[2].imshow(np.squeeze(pred_mask, axis=0)) # предсказаная маска\n",
    "    plt.show()\n",
    "\n",
    "# исходная картинка, истинная маска, предсказанная маска\n",
    "show_predictions(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b243cd7",
   "metadata": {},
   "source": [
    "Unet 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eed8e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Unet(num_classes=14, input_shape=(256, 256, 3)):\n",
    "    img_input = Input(input_shape)\n",
    "\n",
    "    # Block 1\n",
    "    x = Conv2D(64, (3, 3), padding='same', name='block1_conv1')(img_input)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2D(64, (3, 3), padding='same', name='block1_conv2')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    # в Unet основной посыл в том, тобы прокидывать признаки в конец сетки,\n",
    "    # когда уже идёт предсказание маски. Поэтому мы запоминаем этот слой и прокидываем его в конец\n",
    "    # запомним тензор для переноса\n",
    "    block_1_out = Activation('relu')(x)\n",
    "\n",
    "\n",
    "    x = MaxPooling2D()(block_1_out)\n",
    "\n",
    "\n",
    "    # Block 2\n",
    "    x = Conv2D(128, (3, 3), padding='same', name='block2_conv1')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2D(128, (3, 3), padding='same', name='block2_conv2')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    # запомним тензор для переноса\n",
    "    block_2_out = Activation('relu')(x)\n",
    "\n",
    "    x = MaxPooling2D()(block_2_out)\n",
    "\n",
    "\n",
    "    # Block 3\n",
    "    x = Conv2D(256, (3, 3), padding='same', name='block3_conv1')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2D(256, (3, 3), padding='same', name='block3_conv2')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2D(256, (3, 3), padding='same', name='block3_conv3')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    # запомним тензор для переноса\n",
    "    block_3_out = Activation('relu')(x)\n",
    "\n",
    "    x = MaxPooling2D()(block_3_out)\n",
    "\n",
    "\n",
    "    # Block 4\n",
    "    x = Conv2D(512, (3, 3), padding='same', name='block4_conv1')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2D(512, (3, 3), padding='same', name='block4_conv2')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2D(512, (3, 3), padding='same', name='block4_conv3')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    # запомним тензор для переноса\n",
    "    block_4_out = Activation('relu')(x)\n",
    "\n",
    "    # начинаем растягивать картинку\n",
    "    # UP 1\n",
    "    x = Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    # конкатенируем то что получили после 3-го увеличения и блок 3\n",
    "    x = concatenate([x, block_3_out])\n",
    "    x = Conv2D(256, (3, 3), padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2D(256, (3, 3), padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    # UP 2\n",
    "    x = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = concatenate([x, block_2_out])\n",
    "    x = Conv2D(128, (3, 3), padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2D(128, (3, 3), padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    # UP 3\n",
    "    x = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = concatenate([x, block_1_out])\n",
    "    x = Conv2D(64, (3, 3), padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2D(64, (3, 3), padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "\n",
    "    # слой классификатор (14 классов, поэтому softmax)\n",
    "    x = Conv2D(num_classes, (3, 3), activation='softmax', padding='same')(x)\n",
    "\n",
    "    model = Model(img_input, x)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6096a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1 = Unet(3, (256, 256, 3))\n",
    "\n",
    "plot_model(model_1, to_file='model_1.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ae98bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1.compile(optimizer=Adam(),\n",
    "                loss='categorical_crossentropy',\n",
    "                metrics=[dice_coef]) # самописная метрика dice\n",
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "372ebfc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_1 = model_1.fit(x_train, y_train,\n",
    "                      epochs=20,\n",
    "                      batch_size=10,\n",
    "                      validation_data=(x_val, y_val),\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2560ced3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history_1.history['loss'], label='train_loss')\n",
    "plt.plot(history_1.history['val_loss'], label='val_loss')\n",
    "plt.legend()\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e60d1c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history_1.history['val_dice_coef'], label='test')\n",
    "plt.plot(history_1.history['dice_coef'], label='train')\n",
    "plt.legend()\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('dice_coef')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "887f6682",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_1 = model_1.predict(x_val)\n",
    "print(pred_1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2cc52fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "ni = 3\n",
    "for k in range(ni):\n",
    "    plt.figure(figsize=(20,60))\n",
    "\n",
    "    plt.subplot(ni,4,1+k*4)\n",
    "    plt.imshow(x_val[k])\n",
    "\n",
    "    plt.subplot(ni,4,2+k*4)\n",
    "    plt.imshow(y_val[k])\n",
    "\n",
    "    plt.subplot(ni,4,3+k*4)\n",
    "    plt.imshow(pred_1[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29567545",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_predictions(model):\n",
    "\n",
    "    sample_image = x_val[0]\n",
    "    sample_mask = y_val[0]\n",
    "\n",
    "    pred_mask = model.predict(sample_image[None])[..., 0] # нулевой канал, можно любой (можно которого больше)\n",
    "    print(pred_mask.shape)\n",
    "\n",
    "    fig, ax = plt.subplots(1, 3, figsize=(15, 8))\n",
    "\n",
    "    ax[0].imshow(sample_image) # картинка\n",
    "    ax[1].imshow(sample_mask[..., 0]) # истиная маска\n",
    "    ax[2].imshow(np.squeeze(pred_mask, axis=0)) # предсказаная маска\n",
    "    plt.show()\n",
    "\n",
    "# исходная картинка, истинная маска, предсказанная маска\n",
    "show_predictions(model_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ae2bc6",
   "metadata": {},
   "source": [
    "Вывод\n",
    "\n",
    "Улучшить качество обучения помогает архитектура сети и количество эпох обучения: больше - лучше."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5232073",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
